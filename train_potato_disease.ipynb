{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sharv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                                      #Taking Current Directory\n",
    "curr_dir = os.getcwd()\n",
    "train_path = os.path.join(curr_dir,\"datasets\",\"Train\")\n",
    "testing_path = os.path.join(curr_dir,\"datasets\",\"Test\")\n",
    "valid_path = os.path.join(curr_dir,\"datasets\",\"Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set =  tf.keras.utils.image_dataset_from_directory(                #Importing data in training_set\n",
    "    train_path,               \n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"categorical\",\n",
    "    color_mode = \"rgb\",\n",
    "    image_size = (128,128),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_names                                                       #Seeing my classes in training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set =  tf.keras.utils.image_dataset_from_directory(                   #Importing data in validation_set\n",
    "    valid_path,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"categorical\",\n",
    "    color_mode = \"rgb\",\n",
    "    image_size = (128,128),\n",
    "    shuffle = True,\n",
    "    interpolation = \"bilinear\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sharv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sharv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()                                                                        #Creating various layers with 32features, 64features, so on\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = [128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3,  activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size = 3,  activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size = 3,  activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size = 3,  activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size = 3,  activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())                                                                          #Converting 3D image to 1D\n",
    "cnn.add(tf.keras.layers.Dense(units = 1500, activation = 'relu'))                                           #Gives positive output or else 0\n",
    "cnn.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units = 3, activation = 'softmax'))                                           #Takes highest probability image for output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])                     #While using softmax, categorical_crossentropy works better, 0.0001 is training rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 4503      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7790227 (29.72 MB)\n",
      "Trainable params: 7790227 (29.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\sharv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sharv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "29/29 [==============================] - 64s 2s/step - loss: 1.1456 - accuracy: 0.4511 - val_loss: 0.7336 - val_accuracy: 0.6200\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 74s 3s/step - loss: 0.6294 - accuracy: 0.6956 - val_loss: 0.6804 - val_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 77s 3s/step - loss: 0.5132 - accuracy: 0.7700 - val_loss: 0.5977 - val_accuracy: 0.6567\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 68s 2s/step - loss: 0.4310 - accuracy: 0.8178 - val_loss: 0.5333 - val_accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 71s 2s/step - loss: 0.3935 - accuracy: 0.8333 - val_loss: 0.2617 - val_accuracy: 0.9133\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 70s 2s/step - loss: 0.2116 - accuracy: 0.9144 - val_loss: 0.2024 - val_accuracy: 0.9233\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 67s 2s/step - loss: 0.1893 - accuracy: 0.9311 - val_loss: 0.7022 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 70s 2s/step - loss: 0.4332 - accuracy: 0.8333 - val_loss: 0.2381 - val_accuracy: 0.9300\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 67s 2s/step - loss: 0.1577 - accuracy: 0.9478 - val_loss: 0.1358 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 63s 2s/step - loss: 0.1059 - accuracy: 0.9678 - val_loss: 0.2978 - val_accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set, validation_data=validation_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 17s 593ms/step - loss: 0.2032 - accuracy: 0.9200\n",
      "Training accuracy 0.9200000166893005\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print(\"Training accuracy\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 614ms/step - loss: 0.2978 - accuracy: 0.8967\n",
      "Validation accuracy 0.8966666460037231\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print(\"Validation accuracy\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn,\u001b[43msave\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_plant_disease_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save' is not defined"
     ]
    }
   ],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [for in in range(1,11)]\n",
    "plt.plot(epochs, training_history.history['accuracy'], color = 'brown', label = 'Training accuracy')\n",
    "plt.plot(epochs, training_history.history['val_accuracy'], color = 'green', label = 'Validation accuracy')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.title(\"Visualisation of Accuracy Results\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
